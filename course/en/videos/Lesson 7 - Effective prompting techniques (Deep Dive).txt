[Music] Let's explore one of the most practical skills when working with AI. Crafting effective prompts. This might sound technical or complicated, and some guides certainly make it seem that way, but at its heart, it's surprisingly straightforward. Prompting is simply how we apply this course's description competency in practice. clearly communicating what we want, how we want it done, and how we want to interact with our AI assistant throughout the entire process. Think of prompting like explaining a task to a helpful new colleague who's eager to assist, but needs clear directions and expectation setting to do their best work. We'll be using Claude throughout this section, but these tips can be carried over to many other AI systems. You might have heard the term prompt engineering tossed around. Prompt engineering is simply the practice of designing effective instructions for AI systems like Claude. It's about crafting your questions and providing context in ways that help AI assistants understand exactly what you want. What's fascinating is that effective prompting blends familiar human communication skills with a few considerations specific to AI. Many principles that make for good human conversation, such as being clear, providing relevant context, and giving concrete examples, also apply when working with AI. Yet, there are differences, such as being more explicit about things humans could naturally infer, and accommodating the AI's limited context window, and sometimes, depending on the AI you're working with, using specific formatting that machines can easily process. As AI assistants continue to evolve, prompting best practices evolve, too. What works with today's AI systems may be different from what works with tomorrow's. Experimentation is key to discovering what works best for your specific needs. In this video, we'll mainly explore six foundational prompting tips that will go a long way toward helping you effectively communicate and collaborate with Claude and other AI systems. They are give Claude context, show examples of what good looks like, specify output constraints, break complex tasks into steps, ask Claude to think first, and define Claude's role, style, or tone. The first principle is simple but powerful. Be specific and clear about what you want, why you want it, and perhaps most surprisingly, who you are. Let's take a simple prompt. Tell me about climate change. How can we improve this by giving Cloud more context? A more specific contextrich version could look like, explain three major impacts of climate change on agriculture in tropical regions with examples from the past decade. Our baseline prompt was vague and leaves clawed guessing about our interests, level of knowledge, and the depth of detail we're looking for, such as geography and time span. We can even add more context by providing information not just about what we're looking for, but why we're asking and how we'll be using that information that Claude gives us. Now, our prompt looks like this. Explain three major impacts of climate change on agriculture in tropical regions with examples from the past decade. I'm preparing for a job interview at an agricultural research lab in Indonesia. I have a degree in ecology, but no specific knowledge on climate change. write a summary of key concepts that would help me speak intelligently in the interview. All this added context helps tailor Claude's response to your specific situation and knowledge level. This kind of background information is something we naturally provide in human conversations, but might forget to include when talking with Claude. Sometimes showing is better than telling. Providing examples of the kind of output you're looking for can be incredibly effective. This is sometimes called fshot prompting or nshot prompting in technical circles where n is the number of examples given but it's really just about showing the AI examples for it to emulate. For instance, take the following prompt. Please convert this technical statement to plain language. The platform implements end-to-end encryption protocols to safeguard data integrity. Clog may already be able to do this to your satisfaction. So we definitely recommend you just try first without examples and see where it leads you. But let's say you have a very specific style you want Claude to follow, and it's harder to explain than to give examples. Your refreshed prompt could look something like this. Here are two examples of how to convert technical jargon into plain language. Original, the quantum algorithm exhibits quadratic speed up. Plain, the new method solves problems roughly twice as fast as previous methods. Original, the interface leverages intuitive design paradigms. Plain, the design is easy to understand and use. Now, please convert this complex technical manual to plain language. When providing examples, aim to cover the full diversity of possible prompts, such as examples that cover different cases or styles. This helps Claude better understand the broad range of the pattern you want it to follow. Being clear about output constraints, such as the desired format and length of Claude's response, or the language you want Claude to code in, or the color of the buttons on the web page you want Claude to design, also helps ensure you get exactly what you need. Here's an example of clear and detailed description to ensure Claude delivers exactly what you're looking for. Create a clean, modern, single page art portfolio website. Include these main sections: hero, about me, skills, portfolio, projects, experience, and contact. Make the navigation menu sticky and responsive with hamburger menu on mobile. Use a sunset color palette and add a dark light mode toggle in the navigation. Guidance like this helps cloud structure its response to match your expectations. When you have a complicated request, breaking it down into smaller steps helps Cloud follow your thinking and deliver better results. Think about it this way. If you ask a friend to do something for you without specifying how, there's a chance that they may not do it the way you intended them to. We've all been there. Listing out task steps ensures that Claude follows the process you want to in order to accomplish its task. This is sometimes called chain of thought prompting. For example, instead of asking Claude to analyze this quarterly sales data, you might say, "I'd like to analyze this quarterly sales data. Please approach this by looking through our sales records to identify the top performing products, comparing current quarter results to the previous quarter, highlighting any unusual trends or patterns, and then suggesting possible reasons for these trends. By default, you may not need to do this, especially for tasks that are relatively straightforward. Furthermore, modern reasoning models or extended thinking models are increasingly capable of performing step-by-step reasoning on their own, but you can still guide this process to ensure it aligns with your needs. The more variance there is in ways to execute the task well, or the more that proper task execution relies on experience and knowledge you've gained as a domain expert, the more you should consider taking the time to translate that knowledge into Claude. Relatedly, sometimes it can be helpful to explicitly give AI assistants like Claude space to work through its process first before executing its task. This approach helps Claude produce more thorough and well-considered responses. For example, you can add this to your prompt. Before answering, please think through this problem carefully. Consider the different factors involved, potential constraints, and various approaches before recommending the best solution. As I mentioned, modern reasoning or extended thinking models by default think before acting. But if you're working with an AI assistant that does not think first by default, you can still prompt the AI to do so. I want to note the importance of giving the AI assistant space to think before doing its task, not after. If you want that thinking to increase the quality of the AI's work, just like how having space to think before you act is different than acting first, then being asked to explain your thinking afterwards. As a side benefit, this also allows you to better see where the AI assistant might be going astray and thus where you could hone your description competency further by providing more guidance. Specifying how you want cloud to communicate and behave can significantly change how it approaches a task. By specifying the level of expected expertise, the perspective you want it to take, or its communication style, you can guide both Claude's interaction with you and the final result of what it produces. Simply put, who do you want the AI to act as? For example, take this prompt. Please explain how rainbows form from the perspective of an experienced science teacher speaking to a bright 10-year-old who's interested in science. This is also a good way to brainstorm or get feedback. You can specify a general role or even ask Claw to take on the persona of a specific figure, such as Richard Fineman, when asking for physics explanations. Here's another example. As a UX design expert, review this website wireframe and suggest three improvements focusing on user navigation and accessibility. Perhaps the most powerful technique is asking Claude to help improve your prompt. When you're not sure how to ask for something or how to improve your prompt, describe to Claude your issue or situation and ask it to make your prompt better or write your prompt for you. I'm trying to get you, Claude, to help me with goal. I'm not sure how to phrase my request to get the best results. Can you help me craft an effective prompt for this? Here's where Claude and other AI assistants may vary most in terms of performance. So, we suggest you experiment with different models as part of practicing delegation. Effective prompting is iterative and experimental. AI systems and best practices are constantly evolving. So, what works today may change tomorrow. Your first attempt won't always yield the perfect result, and that's expected. When a response isn't quite what you need, try refining your approach by playing around with any of the techniques we mentioned, such as add more specificity or context. Provide examples of your desired output. Break the task into smaller steps and try a different technique or combination of techniques. You can also ask for variations such as, "Can you give me three different versions of this?" You can request different formats such as, "Instead of a paragraph, could you present this in an interactive artifact?" Note that artifacts are a unique way that Claude can create outputs that may be easier to understand or more interesting to digest. You can also check confidence, such as for factual questions, you can ask, "How confident are you about this answer?" You can also reset the conversation entirely. Sometimes starting a fresh conversation gives better results than trying to correct the conversation that's gone off track. Use each interaction as feedback to improve your next prompt. Over time, you'll develop an intuition for how to communicate effectively with all AI systems. As you apply these techniques in practice, here's some guidance to recap. Some patterns consistently work well. Starting with a clear task overview statement, including format specifications and examples, setting explicit constraints or requirements, providing rich and relevant background information, and common mistakes to avoid are assuming that Claude can read your mind, or overloading a single prompt or conversation with multiple unrelated tasks, being too vague about what success looks like, and not providing feedback on previous responses. To recap, effective communication with AI systems like Claude combines timeless human communication principles with AI specific techniques. The approaches we've covered will serve you well across different AI systems. These six principles together with the secret weapon of asking Cloud for help form a solid toolkit for applying the description competence to your AI interactions. Iteration and practice here is the key to Swift improvement and mastery. Remember that prompt engineering is an evolving practice. As models improve, some specific techniques become less necessary. However, these principles of good communication are still relevant even if the way we apply them changes. Maintain a spirit of experimentation and adapt your approach based on your results. 
